{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53b8MsQWoAlU",
        "outputId": "59f2e775-f859-4869-a300-be7f5b98dfbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX1-4uqfoGKD",
        "outputId": "9368e8b1-da6b-461d-c468-2873cd35d5bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import splitfolders\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "0uybuTqg72n2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/Dataset'"
      ],
      "metadata": {
        "id": "QvbhEdZPpSlZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Dataset into 3 part: Train, Val, and Test"
      ],
      "metadata": {
        "id": "jArrkMrn-QSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio(\n",
        "    base_dir,\n",
        "    output='Capstone',\n",
        "    ratio=(.7, 0.2,0.1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCCCouqn6xlp",
        "outputId": "e256747d-1fb4-47f7-9042-2e60db7e43ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2375 files [01:50, 21.40 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'Capstone/train'\n",
        "val_dir = 'Capstone/val' \n",
        "test_dir = 'Capstone/test'\n",
        "\n",
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sxcPxlg8HEX",
        "outputId": "9ced7fe9-6a71-4cf9-9e6a-be55e73b85c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BrownSpot', 'LeafBlast', 'Healthy', 'Hispa']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = ['Healthy', 'Hispa', 'BrownSpot', 'LeafBlast']"
      ],
      "metadata": {
        "id": "46T6UAnh8xfE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "TPO-Bcif-Nbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=0.45, \n",
        "                    width_shift_range=0.2,\n",
        "                     height_shift_range=0.2,\n",
        "                     zoom_range=(0.2), \n",
        "                     fill_mode='nearest', \n",
        "                    horizontal_flip=True,\n",
        "                    )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "Wl-hKSrb80fl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size=(150,150), \n",
        "    batch_size=32, \n",
        "    shuffle=True,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "TIydq1GC-kEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073ef526-cd5c-4c60-a99b-b65207c42a09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1661 images belonging to 4 classes.\n",
            "Found 474 images belonging to 4 classes.\n",
            "Found 240 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "CKs4bbfQ-3X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience=3)"
      ],
      "metadata": {
        "id": "P-tOHtfJ-sXg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience = 2,\n",
        "    verbose=1,\n",
        "    factor=0.3,\n",
        "    min_lr=0.000001\n",
        ")"
      ],
      "metadata": {
        "id": "pMLBJixrX9f-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "tfmodel = InceptionV3(weights='imagenet', \n",
        "                                include_top=False, \n",
        "                                input_shape=(150,150,3))"
      ],
      "metadata": {
        "id": "it6kHkh-YUMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3c98a5-3007-4cb6-f997-b9d589ed3699"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "g-0rzujKYugj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(tfmodel)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.4))      \n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SFFCEVWW_AWu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HR6QHBfA3q3",
        "outputId": "b9e9d1a4-5d95-4a2c-bb01-40cf717de00d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 3, 3, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                4112      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,987,380\n",
            "Trainable params: 22,952,948\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=50,\n",
        "                    callbacks=[monitor_val_acc, reduce_lr],\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ogaD7mAkwm",
        "outputId": "f3873422-b4d8-4a50-9f26-85d9250ddda7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "52/52 [==============================] - 274s 5s/step - loss: 0.9832 - accuracy: 0.6213 - val_loss: 0.9329 - val_accuracy: 0.6350 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 257s 5s/step - loss: 0.7912 - accuracy: 0.6815 - val_loss: 0.8429 - val_accuracy: 0.6540 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 260s 5s/step - loss: 0.7776 - accuracy: 0.6954 - val_loss: 0.8084 - val_accuracy: 0.6561 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 258s 5s/step - loss: 0.7272 - accuracy: 0.7321 - val_loss: 0.7681 - val_accuracy: 0.6835 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 261s 5s/step - loss: 0.7217 - accuracy: 0.7213 - val_loss: 0.7623 - val_accuracy: 0.6962 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 260s 5s/step - loss: 0.7107 - accuracy: 0.7273 - val_loss: 0.7363 - val_accuracy: 0.7025 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 260s 5s/step - loss: 0.7077 - accuracy: 0.7285 - val_loss: 0.7475 - val_accuracy: 0.6983 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.7423\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "52/52 [==============================] - 262s 5s/step - loss: 0.6461 - accuracy: 0.7423 - val_loss: 0.7959 - val_accuracy: 0.6751 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 262s 5s/step - loss: 0.6228 - accuracy: 0.7688 - val_loss: 0.7197 - val_accuracy: 0.7068 - lr: 3.0000e-05\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 261s 5s/step - loss: 0.5808 - accuracy: 0.7815 - val_loss: 0.7144 - val_accuracy: 0.7046 - lr: 3.0000e-05\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 264s 5s/step - loss: 0.5566 - accuracy: 0.7809 - val_loss: 0.7054 - val_accuracy: 0.7173 - lr: 3.0000e-05\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 261s 5s/step - loss: 0.5526 - accuracy: 0.7911 - val_loss: 0.7027 - val_accuracy: 0.7215 - lr: 3.0000e-05\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 266s 5s/step - loss: 0.5772 - accuracy: 0.7911 - val_loss: 0.7061 - val_accuracy: 0.7152 - lr: 3.0000e-05\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.8037\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "52/52 [==============================] - 261s 5s/step - loss: 0.5329 - accuracy: 0.8037 - val_loss: 0.7015 - val_accuracy: 0.7173 - lr: 3.0000e-05\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 287s 6s/step - loss: 0.5227 - accuracy: 0.8043 - val_loss: 0.6931 - val_accuracy: 0.7236 - lr: 9.0000e-06\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 285s 6s/step - loss: 0.4982 - accuracy: 0.8134 - val_loss: 0.6918 - val_accuracy: 0.7236 - lr: 9.0000e-06\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 265s 5s/step - loss: 0.5277 - accuracy: 0.8025 - val_loss: 0.6930 - val_accuracy: 0.7257 - lr: 9.0000e-06\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 263s 5s/step - loss: 0.5144 - accuracy: 0.8110 - val_loss: 0.7095 - val_accuracy: 0.7173 - lr: 9.0000e-06\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 288s 6s/step - loss: 0.5328 - accuracy: 0.7983 - val_loss: 0.6936 - val_accuracy: 0.7278 - lr: 9.0000e-06\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 284s 5s/step - loss: 0.5028 - accuracy: 0.8152 - val_loss: 0.6851 - val_accuracy: 0.7342 - lr: 9.0000e-06\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 263s 5s/step - loss: 0.5070 - accuracy: 0.8110 - val_loss: 0.6856 - val_accuracy: 0.7447 - lr: 9.0000e-06\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 262s 5s/step - loss: 0.4816 - accuracy: 0.8224 - val_loss: 0.6824 - val_accuracy: 0.7447 - lr: 9.0000e-06\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.8296\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
            "52/52 [==============================] - 289s 6s/step - loss: 0.4732 - accuracy: 0.8296 - val_loss: 0.6928 - val_accuracy: 0.7363 - lr: 9.0000e-06\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 286s 6s/step - loss: 0.4749 - accuracy: 0.8176 - val_loss: 0.6939 - val_accuracy: 0.7321 - lr: 2.7000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yrj7R1OX2bGm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}